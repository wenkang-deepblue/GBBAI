import streamlit as st
import base64
import openai
from google.auth import default, transport
import google.auth
from google.oauth2 import service_account
import google.auth.transport.requests
import vertexai
import re
from PIL import Image
import io
import base64
import requests

credentials_info = st.secrets["GOOGLE_APPLICATION_CREDENTIALS"]
creds = service_account.Credentials.from_service_account_info(
    credentials_info,
    scopes=["https://www.googleapis.com/auth/cloud-platform"]
)

# åˆ·æ–°å‡­è¯
auth_req = google.auth.transport.requests.Request()
creds.refresh(auth_req)

# åˆå§‹åŒ– Vertex AI
project_id = "lwk-genai-test"
location = "us-central1"
vertexai.init(project=project_id, location=location, credentials=creds)

# è®¾ç½® OpenAI å®¢æˆ·ç«¯çš„ URL
url = f"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/{project_id}/locations/{location}/endpoints/openapi"

# åˆ›å»º OpenAI å®¢æˆ·ç«¯
client = openai.OpenAI(
    base_url=url,         
    api_key=creds.token,
)

APP_ID = "llama_chat"

def load_gif(gif_url):
    response = requests.get(gif_url)
    if response.status_code == 200:
        contents = response.content
        data_url = base64.b64encode(contents).decode("utf-8")
        return f"data:image/gif;base64,{data_url}"
    else:
        st.error(f"æ— æ³•åŠ è½½GIFå›¾åƒï¼šHTTPçŠ¶æ€ç  {response.status_code}")
        return ""

# åŠ è½½GIFå›¾ç‰‡
thinking_gif = load_gif("https://storage.googleapis.com/ghackathon/typing-dots-40.gif")

# Streamlit åº”ç”¨ç•Œé¢
left_co, cent_co,last_co = st.columns([0.39,0.31,0.30])
with cent_co:
    st.title(":blue[GBB] :rainbow[AI]")
left_co, cent_co,last_co = st.columns([0.43,0.37,0.3])
with cent_co:
    st.caption(":blue[_Llama3.1èŠå¤©æœºå™¨äºº_]")
st.image('https://storage.googleapis.com/ghackathon/page_18_zh.png')
left_co, cent_co,last_co = st.columns([0.24,0.51,0.25])
with cent_co:
    st.subheader('', divider='rainbow')

#ç»§ç»­streamlit sidebarç•Œé¢
with st.sidebar:
    left_co, cent_co,last_co = st.columns([0.34,0.33,0.33])
    with cent_co:
        st.image('https://storage.googleapis.com/ghackathon/image2.gif')
    left_co, cent_co,last_co = st.columns([0.36,0.32,0.32])
    with cent_co:
        st.title(":blue[GBB] :rainbow[AI]")
    temperature = st.slider("è°ƒæ•´æ¨¡å‹Temperature", min_value=0.0, max_value=2.0, value=1.0, help=(
        """
        Temperatureç”¨äºå“åº”ç”ŸæˆæœŸé—´çš„é‡‡æ ·ï¼Œè¿™å‘ç”Ÿåœ¨åº”ç”¨ topP å’Œ topK æ—¶ã€‚Temperatureæ§åˆ¶äº†tokené€‰æ‹©ä¸­çš„éšæœºç¨‹åº¦ã€‚å¯¹äºéœ€è¦è¾ƒå°‘å¼€æ”¾å¼æˆ–åˆ›é€ æ€§å“åº”çš„æç¤ºï¼Œè¾ƒä½çš„temperatureæ˜¯å¥½çš„ï¼Œè€Œè¾ƒé«˜çš„temperatureå¯ä»¥å¯¼è‡´æ›´å¤šæ ·åŒ–æˆ–åˆ›é€ æ€§çš„ç»“æœã€‚Temperatureä¸º 0 æ„å‘³ç€å§‹ç»ˆé€‰æ‹©æœ€é«˜æ¦‚ç‡çš„tokenã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç»™å®šæç¤ºçš„å“åº”å¤§å¤šæ˜¯ç¡®å®šçš„ï¼Œä½†ä»æœ‰å¯èƒ½å‡ºç°å°‘é‡å˜åŒ–ã€‚
        
        å¦‚æœæ¨¡å‹è¿”å›çš„å“åº”è¿‡äºé€šç”¨ã€å¤ªçŸ­æˆ–æ¨¡å‹ç»™å‡ºå›é€€å“åº”ï¼Œè¯·å°è¯•æé«˜temperatureã€‚
        """
    ))
    top_p = st.slider ("è°ƒæ•´æ¨¡å‹Top_p", min_value=0.00, max_value=1.00, value=0.95, help=(
        """
        Top-P æ”¹å˜äº†æ¨¡å‹é€‰æ‹©è¾“å‡ºtokensçš„æ–¹å¼ã€‚TokensæŒ‰ç…§ä»æœ€å¯èƒ½ï¼ˆè§top-Kï¼‰åˆ°æœ€ä¸å¯èƒ½çš„é¡ºåºè¿›è¡Œé€‰æ‹©ï¼Œç›´åˆ°å®ƒä»¬çš„æ¦‚ç‡ä¹‹å’Œç­‰äºtop-På€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœtoken Aã€Bå’ŒCçš„æ¦‚ç‡åˆ†åˆ«ä¸º0.3ã€0.2å’Œ0.1ï¼Œtop-På€¼ä¸º0.5ï¼Œé‚£ä¹ˆæ¨¡å‹å°†ä½¿ç”¨æ¸©åº¦ä»Aæˆ–Bä¸­é€‰æ‹©ä¸‹ä¸€ä¸ªtokenï¼Œå¹¶æ’é™¤Cä½œä¸ºå€™é€‰ã€‚

        æŒ‡å®šè¾ƒä½çš„å€¼ä¼šå¾—åˆ°è¾ƒå°‘çš„éšæœºå“åº”ï¼ŒæŒ‡å®šè¾ƒé«˜çš„å€¼ä¼šå¾—åˆ°æ›´å¤šçš„éšæœºå“åº”ã€‚
        """
    ))
    
    generic_chat = "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„äººç±»åŠ©æ‰‹ï¼Œè¯·ç”¨ç”¨æˆ·è·Ÿä½ å¯¹è¯çš„è¯­è¨€æ¥è¿›è¡Œä¸ç”¨æˆ·çš„å¯¹è¯"
    python_expert = "ä½ æ˜¯ä¸€ä¸ªpythonä¸“å®¶ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·ç”Ÿæˆpythonä»£ç ï¼Œè§£é‡Špythonä»£ç ï¼Œå®Œå–„pythonä»£ç "
    
    st.subheader('', divider='rainbow')
    
    system_instruction_option = ""
        
    system_instruction_option1 = st.radio(
        "è¯·é€‰æ‹©AIçš„è§’è‰²ï¼š",
        ("å‹å¥½çš„åŠ©æ‰‹", "Pythonä¸“å®¶", "è‡ªå®šä¹‰"),
        index=None,
    )
    
    if system_instruction_option1 == "è‡ªå®šä¹‰":
        system_instruction_option2 = st.text_area ("è¯·åœ¨æ­¤è‡ªç”±å®šä¹‰AIçš„è§’è‰²ï¼š", "")
        submitted = st.button("æäº¤")
        if submitted:
            st.session_state.custom_role_description = system_instruction_option2
    
    if system_instruction_option1 == "å‹å¥½çš„åŠ©æ‰‹":
        system_instruction_option = generic_chat
    elif system_instruction_option1 == "Pythonä¸“å®¶":
        system_instruction_option = python_expert
    elif system_instruction_option1 == "è‡ªå®šä¹‰" and "custom_role_description" in st.session_state:
        system_instruction_option = st.session_state.custom_role_description
    
    if system_instruction_option:
        st.write(f"æ‚¨é€‰æ‹©çš„AIè§’è‰²æè¿°ä¸ºï¼š{system_instruction_option}")
    else:
        st.error("è¯·é€‰æ‹©æˆ–å®šä¹‰AIè§’è‰²")
   
    st.text("")
    st.page_link("homepage.py", label="ä¸»é¡µ", icon="ğŸ ")
    st.page_link("pages/page_1.py", label="æ–‡æœ¬ç”Ÿæˆ", icon="ğŸ“–")
    st.page_link("pages/page_2.py", label="è§†é¢‘ç†è§£", icon="ğŸï¸")
    st.page_link("pages/page_3.py", label="æ–‡æœ¬ç¿»è¯‘", icon="ğŸ‡ºğŸ‡³")
    st.page_link("pages/page_4.py", label="RAGæœç´¢", icon="ğŸ”")
    st.page_link("pages/page_5.py", label="åª’ä½“æœç´¢", icon="ğŸ¥")
    st.page_link("pages/page_6.py", label="å›¾ç‰‡ç”Ÿæˆ", icon="ğŸ¨")
    st.page_link("pages/page_7.py", label="èŠå¤©æœºå™¨äºº", icon="ğŸ’¬")
    st.page_link("pages/page_8.py", label="æ¸¸æˆå®¢æœå¹³å°", icon="ğŸ¤–")
    st.page_link("pages/page_9.py", label="ç”µå•†å®¢æœå¹³å°", icon="ğŸ¤–")
    st.page_link("pages/page_10.py", label="Claude3.5èŠå¤©æœºå™¨äºº", icon="ğŸ’¬")
    st.page_link("pages/page_11.py", label="Llama3.1èŠå¤©æœºå™¨äºº", icon="ğŸ’¬")
    st.page_link("https://pantheon.corp.google.com/translation/hub", label="GCPç¿»è¯‘é—¨æˆ·", icon="ğŸŒ")
    st.page_link("https://pantheon.corp.google.com/vertex-ai/generative/multimodal/gallery", label="GCPæ§åˆ¶å° - Gemini", icon="ğŸŒ")
    st.page_link("https://pantheon.corp.google.com/gen-app-builder/engines", label="GCPæ§åˆ¶å° - App Builder", icon="ğŸŒ")
    st.text("")
    st.subheader('', divider='rainbow')
    st.text("")
    left_co, cent_co,last_co = st.columns([0.39,0.31,0.30])
    with cent_co:
        st.write('Â© GBB')
    left_co, cent_co,last_co = st.columns([0.09,0.83,0.08])
    with cent_co:
        st.write(':grey[Designed & Developed by] :blue[ææ–‡åº·]')
    left_co, cent_co,last_co = st.columns([0.22,0.6,0.18])
    with cent_co:
        st.write(':grey[Powered by] **Vertex AI**')

# LLaMA model
MODEL_ID = 'meta/llama3-405b-instruct-maas'

def generate_text(messages):
    response = client.chat.completions.create(
        model=MODEL_ID,
        messages=messages,
        temperature=temperature,
        top_p=top_p,
        max_tokens=4000,
    )
    
    # è·å–æ¶ˆæ¯å†…å®¹
    content = response.choices[0].message.content
    
    # ç§»é™¤å¼€å¤´çš„å¤šä¸ª"assistant"
    content = re.sub(r'\n+', '', re.sub(r'^(assistant)+', '', content).lstrip())
   
    # è¿”å›å¤„ç†åçš„æ¶ˆæ¯å†…å®¹
    return content.strip()
    
# åˆå§‹åŒ–Streamlitåº”ç”¨
if f"{APP_ID}_messages" not in st.session_state:
    st.session_state[f"{APP_ID}_messages"] = []
if f"{APP_ID}_current_role" not in st.session_state:
    st.session_state[f"{APP_ID}_current_role"] = None

if system_instruction_option and system_instruction_option != st.session_state[f"{APP_ID}_current_role"]:
    st.session_state[f"{APP_ID}_current_role"] = system_instruction_option
    st.session_state[f"{APP_ID}_messages"] = [{"role": "system", "content": system_instruction_option}]

for msg in st.session_state.get(f"{APP_ID}_messages", [])[1:]:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    if not st.session_state.get(f"{APP_ID}_current_role"):
        st.error("ğŸ‘ˆè¯·å®šä¹‰ä¸€ç§è§’è‰²ï¼šåœ¨èœå•ä¸­é€‰æ‹©æˆ–è€…è‡ªå®šä¹‰")
        st.stop()
    else:
        st.session_state[f"{APP_ID}_messages"].append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å ä½ç¬¦æ¥æ˜¾ç¤ºGIF
        gif_placeholder = st.empty()

        # æ˜¾ç¤ºGIFï¼Œä¸åŒ…å«ä»»ä½•æ–‡æœ¬
        gif_placeholder.markdown(
            f'<div style="display: flex; justify-content: center;">'
            f'<img src="{thinking_gif}" alt="" style="width:30px;">'
            f'</div>',
            unsafe_allow_html=True
        )

        # ç”ŸæˆAIå“åº”
        response = generate_text(st.session_state[f"{APP_ID}_messages"])

        # ç§»é™¤GIF
        gif_placeholder.empty()

    st.session_state[f"{APP_ID}_messages"].append({"role": "assistant", "content": response})
    st.chat_message("assistant").write(response)
